<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">
  <meta name="google-site-verification" content="LiWuK0jxrq55oR5-aNOK6r0wFuUC8EvSlpNYhiiBkDk">
  <meta name="baidu-site-verification" content="code-MRwc3a52M3">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/animate.css@3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css" integrity="sha256-Vzbj7sDDS/woiFS3uNKo8eIuni59rjyNGtXfstRzStA=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/themes/blue/pace-theme-minimal.css">
  <script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js" integrity="sha256-gqd7YTjg/BtfqWSwsJOvndl0Bxc8gFImLEkXQT8+qj0=" crossorigin="anonymous"></script>

<script class="next-config" data-name="main" type="application/json">{"hostname":"zhengjun.top","root":"/","images":"/images","scheme":"Pisces","darkmode":false,"version":"8.8.2","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":true,"bookmark":{"enable":true,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.json","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js"></script>
<meta name="description" content="AF_SP_RAW vs AF_SP 原文 sp-request-reply-01.txt For understanding how it works, read the REQ&#x2F;REP RFC:">
<meta property="og:type" content="article">
<meta property="og:title" content="nanomsg-AF_SP_RAW vs AF_SP">
<meta property="og:url" content="http://zhengjun.top/2019/07/15/%E5%BC%80%E6%BA%90%E5%BA%93/zmq/nanomsg-AF-SP-RAW-vs-AF-SP/index.html">
<meta property="og:site_name" content="郑君的学习笔记">
<meta property="og:description" content="AF_SP_RAW vs AF_SP 原文 sp-request-reply-01.txt For understanding how it works, read the REQ&#x2F;REP RFC:">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2019-07-15T05:39:58.000Z">
<meta property="article:modified_time" content="2019-07-15T05:41:10.000Z">
<meta property="article:author" content="郑  君">
<meta property="article:tag" content="zmq">
<meta property="article:tag" content="nanomsg">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="http://zhengjun.top/2019/07/15/%E5%BC%80%E6%BA%90%E5%BA%93/zmq/nanomsg-AF-SP-RAW-vs-AF-SP/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"http://zhengjun.top/2019/07/15/%E5%BC%80%E6%BA%90%E5%BA%93/zmq/nanomsg-AF-SP-RAW-vs-AF-SP/","path":"2019/07/15/开源库/zmq/nanomsg-AF-SP-RAW-vs-AF-SP/","title":"nanomsg-AF_SP_RAW vs AF_SP"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>nanomsg-AF_SP_RAW vs AF_SP | 郑君的学习笔记</title>
  




  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">
<!-- hexo injector head_end end --><link rel="alternate" href="/atom.xml" title="郑君的学习笔记" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">郑君的学习笔记</p>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">要比昨天进步一点点</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu">
        <li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li>
        <li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li>
        <li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签<span class="badge">214</span></a></li>
        <li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类<span class="badge">80</span></a></li>
        <li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档<span class="badge">1272</span></a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</div>
        
  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-overview-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="郑  君"
      src="/images/avatar.png">
  <p class="site-author-name" itemprop="name">郑  君</p>
  <div class="site-description" itemprop="description">C++，golang，Java，Python，Kotlin，区块链，全栈</div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">1272</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">80</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">214</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author site-overview-item animated">
      <span class="links-of-author-item">
        <a href="https://github.com/ZhengHanYunBlog" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;ZhengHanYunBlog" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:zhenghanyun2021@126.com" title="E-Mail → mailto:zhenghanyun2021@126.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://www.youtube.com/channel/UCmh8TlSil0IrCA-AQ9Xx9_Q" title="YouTube → https:&#x2F;&#x2F;www.youtube.com&#x2F;channel&#x2F;UCmh8TlSil0IrCA-AQ9Xx9_Q" rel="noopener" target="_blank"><i class="fab fa-youtube fa-fw"></i>YouTube</a>
      </span>
  </div>



        </div>
      </div>
        <div class="back-to-top animated" role="button" aria-label="返回顶部">
          <i class="fa fa-arrow-up"></i>
          <span>0%</span>
        </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="reading-progress-bar"></div>
  <a role="button" class="book-mark-link book-mark-link-fixed"></a>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://zhengjun.top/2019/07/15/%E5%BC%80%E6%BA%90%E5%BA%93/zmq/nanomsg-AF-SP-RAW-vs-AF-SP/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="郑  君">
      <meta itemprop="description" content="C++，golang，Java，Python，Kotlin，区块链，全栈">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="郑君的学习笔记">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          nanomsg-AF_SP_RAW vs AF_SP
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2019-07-15 13:39:58 / 修改时间：13:41:10" itemprop="dateCreated datePublished" datetime="2019-07-15T13:39:58+08:00">2019-07-15</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%BC%80%E6%BA%90%E5%BA%93/" itemprop="url" rel="index"><span itemprop="name">开源库</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%BC%80%E6%BA%90%E5%BA%93/c/" itemprop="url" rel="index"><span itemprop="name">c++</span></a>
        </span>
    </span>

  
    <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv">
      <span class="post-meta-item-icon">
        <i class="far fa-eye"></i>
      </span>
      <span class="post-meta-item-text">阅读次数：</span>
      <span id="busuanzi_value_page_pv"></span>
    </span>
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>26k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>24 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <p>AF_SP_RAW vs AF_SP</p>
<p><a target="_blank" rel="noopener" href="https://www.freelists.org/post/nanomsg/AF-SP-RAW-vs-AF-SP,1">原文</a></p>
<p><a target="_blank" rel="noopener" href="https://raw.githubusercontent.com/nanomsg/nanomsg/master/rfc/sp-request-reply-01.txt">sp-request-reply-01.txt</a></p>
<p>For understanding how it works, read the REQ/REP RFC:</p>
<span id="more"></span>

<p>Internet Engineering Task Force                          M. Sustrik, Ed.<br>Internet-Draft<br>Intended status: Informational                               August 2013<br>Expires: February 2, 2014</p>
<pre><code>               Request/Reply Scalability Protocol
                      sp-request-reply-01
</code></pre>
<p>Abstract</p>
<p>   This document defines a scalability protocol used for distributing<br>   processing tasks among arbitrary number of stateless processing nodes<br>   and returning the results of the processing.</p>
<p>Status of This Memo</p>
<p>   This Internet-Draft is submitted in full conformance with the<br>   provisions of BCP 78 and BCP 79.</p>
<p>   Internet-Drafts are working documents of the Internet Engineering<br>   Task Force (IETF).  Note that other groups may also distribute<br>   working documents as Internet-Drafts.  The list of current Internet-<br>   Drafts is at <a target="_blank" rel="noopener" href="http://datatracker.ietf.org/drafts/current/">http://datatracker.ietf.org/drafts/current/</a>.</p>
<p>   Internet-Drafts are draft documents valid for a maximum of six months<br>   and may be updated, replaced, or obsoleted by other documents at any<br>   time.  It is inappropriate to use Internet-Drafts as reference<br>   material or to cite them other than as “work in progress.”</p>
<p>   This Internet-Draft will expire on February 2, 2014.</p>
<p>Copyright Notice</p>
<p>   Copyright (c) 2013 IETF Trust and the persons identified as the<br>   document authors.  All rights reserved.</p>
<p>   This document is subject to BCP 78 and the IETF Trust’s Legal<br>   Provisions Relating to IETF Documents<br>   (<a target="_blank" rel="noopener" href="http://trustee.ietf.org/license-info">http://trustee.ietf.org/license-info</a>) in effect on the date of<br>   publication of this document.  Please review these documents<br>   carefully, as they describe your rights and restrictions with respect<br>   to this document.  Code Components extracted from this document must<br>   include Simplified BSD License text as described in Section 4.e of<br>   the Trust Legal Provisions and are provided without warranty as<br>   described in the Simplified BSD License.</p>
<p>Sustrik                 Expires February 2, 2014                [Page 1]<br><br>Internet-Draft              Request/Reply SP                 August 2013</p>
<ol>
<li> Introduction</li>
</ol>
<p>   One of the most common problems in distributed applications is how to<br>   delegate a work to another processing node and get the result back to<br>   the original node.  In other words, the goal is to utilise the CPU<br>   power of a remote node.</p>
<p>   There’s a wide range of RPC systems addressing the problem, however,<br>   instead of relying on simple RPC algorithm, we will aim at solving a<br>   more general version of the problem.  First, we want to issue<br>   processing requests from multiple clients, not just a single one.<br>   Second, we want to distribute the tasks to any number processing<br>   nodes instead of a single one so that the processing can be scaled up<br>   by adding new processing nodes as necessary.</p>
<p>   Solving the generalised problem requires that the algorithm executing<br>   the task in question – also known as “service” – is stateless.</p>
<p>   To put it simply, the service is called “stateless” when there’s no<br>   way for the user to distinguish whether a request was processed by<br>   one instance of the service or another one.</p>
<p>   So, for example, a service which accepts two integers and multiplies<br>   them is stateless.  Request for “2x2” is always going to produce “4”,<br>   no matter what instance of the service have computed it.</p>
<p>   Service that accepts empty requests and produces the number of<br>   requests processed so far (1, 2, 3 etc.), on the other hand, is not<br>   stateless.  To prove it you can run two instances of the service.<br>   First reply, no matter which instance produces it is going to be 1.<br>   Second reply though is going to be either 2 (if processed by the same<br>   instance as the first one) or 1 (if processed by the other instance).<br>   You can distinguish which instance produced the result.  Thus,<br>   according to the definition, the service is not stateless.</p>
<p>   Despite the name, being “stateless” doesn’t mean that the service has<br>   no state at all.  Rather it means that the service doesn’t retain any<br>   business-logic-related state in-between processing two subsequent<br>   requests.  The service is, of course, allowed to have state while<br>   processing a single request.  It can also have state that is<br>   unrelated to its business logic, say statistics about the processing<br>   that are used for administrative purposes and never returned to the<br>   clients.</p>
<p>   Also note that “stateless” doesn’t necessarily mean “fully<br>   deterministic”.  For example, a service that generates random numbers<br>   is non-deterministic.  However, the client, after receiving a new</p>
<p>Sustrik                 Expires February 2, 2014                [Page 2]<br><br>Internet-Draft              Request/Reply SP                 August 2013</p>
<p>   random number cannot tell which instance has produced it, thus, the<br>   service can be considered stateless.</p>
<p>   While stateless services are often implemented by passing the entire<br>   state inside the request, they are not required to do so.  Especially<br>   when the state is large, passing it around in each request may be<br>   impractical.  In such cases, it’s typically just a reference to the<br>   state that’s passed in the request, such as ID or path.  The state<br>   itself can then be retrieved by the service from a shared database, a<br>   network file system or similar storage mechanism.</p>
<p>   Requiring services to be stateless serves a specific purpose.  It<br>   allows for using any number of service instances to handle the<br>   processing load.  After all, the client won’t be able to tell the<br>   difference between replies from instance A and replies from instance<br>   B.  You can even start new instances on the fly and get away with it.<br>   The client still won’t be able to tell the difference.  In other<br>   words, statelessness is a prerequisite to make your service cluster<br>   fully scalable.</p>
<p>   Once it is ensured that the service is stateless there are several<br>   topologies for a request/reply system to form.  What follows are the<br>   most common:</p>
<ol>
<li><p>One client sends a request to one server and gets a reply.  The<br> common RPC scenario.</p>
</li>
<li><p>Many clients send requests to one server and get replies.  The<br> classic client/server model.  Think of a database server and<br> database clients.  Alternatively think of a messaging broker and<br> messaging clients.</p>
</li>
<li><p>One client send requests to many servers and gets replies.  The<br> load-balancer model.  Think of HTTP load balancers.</p>
</li>
<li><p>Many clients send requests to be processed by many servers.  The<br> “enterprise service bus” model.  In the simplest case the bus can<br> be implemented as a simple hub-and-spokes topology.  In complex<br> cases the bus can span multiple physical locations or multiple<br> organisations with intermediate nodes at the boundaries<br> connecting different parts of the topology.</p>
</li>
</ol>
<p>   In addition to distributing tasks to processing nodes, request/reply<br>   model comes with full end-to-end reliability.  The reliability<br>   guarantee can be defined as follows: As long as the client is alive<br>   and there’s at least one server accessible from the client, the task<br>   will eventually get processed and the result will be delivered back<br>   to the client.</p>
<p>Sustrik                 Expires February 2, 2014                [Page 3]<br><br>Internet-Draft              Request/Reply SP                 August 2013</p>
<p>   End-to-end reliability is achieved, similar to TCP, by re-sending the<br>   request if the client believes the original instance of the request<br>   has failed.  Typically, request is believed to have failed when<br>   there’s no reply received within a specified time.</p>
<p>   Note that, unlike with TCP, the reliability algorithm is resistant to<br>   a server failure.  Even if server fails while processing a request,<br>   the request will be re-sent and eventually processed by a different<br>   instance of the server.</p>
<p>   As can be seen from the above, one request may be processed multiple<br>   times.  For example, reply may be lost on its way back to the client.<br>   Client will assume that the request was not processed yet, it will<br>   resend it and thus cause duplicate execution of the task.</p>
<p>   Some applications may want to prevent duplicate execution of tasks.<br>   It often turns out that hardening such applications to be idempotent<br>   is relatively easy as they already possess the tools to do so.  For<br>   example, a payment processing server already has access to a shared<br>   database which it can use to verify that the payment with specified<br>   ID was not yet processed.</p>
<p>   On the other hand, many applications don’t care about occasional<br>   duplicate processed tasks.  Therefore, request/reply protocol does<br>   not require the service to be idempotent.  Instead, the idempotence<br>   issue is left to the user to decide on.</p>
<p>   Finally, it should be noted that this specification discusses several<br>   features that are of little use in simple topologies and are rather<br>   aimed at large, geographically or organisationally distributed<br>   topologies.  Features like channel prioritisation and loop avoidance<br>   fall into this category.</p>
<ol start="2">
<li> Underlying protocol</li>
</ol>
<p>   The request/reply protocol can be run on top of any SP mapping, such<br>   as, for example, SP TCPmapping [SPoverTCP].</p>
<p>   Also, given that SP protocols describe the behaviour of entire<br>   arbitrarily complex topology rather than of a single node-to-node<br>   communication, several underlying protocols can be used in parallel.<br>   For example, a client may send a request via WebSocket, then, on the<br>   edge of the company network an intermediary node may retransmit it<br>   using TCP etc.</p>
<p>Sustrik                 Expires February 2, 2014                [Page 4]<br><br>Internet-Draft              Request/Reply SP                 August 2013</p>
<p>   +—+  WebSocket  +—+    TCP    +—+<br>   |   |————-|   |———–|   |<br>   +—+             +—+           +—+<br>                      | |<br>        +—+   IPC   | |  SCTP  +—+    DCCP   +—+<br>        |   |———+ +——–|   |———–|   |<br>        +—+                    +—+           +—+</p>
<ol start="3">
<li> Overview of the algorithm</li>
</ol>
<p>   Request/reply protocol defines two different endpoint types: The<br>   requester or REQ (the client) and the replier or REP (the service).</p>
<p>   REQ endpoint can be connected only to a REP endpoint.  REP endpoint<br>   can be connected only to the REQ endpoint.  If the underlying<br>   protocol indicates that there’s an attempt to create a channel to an<br>   incompatible endpoint, the channel MUST NOT be used.  In the case of<br>   TCP mapping, for example, the underlying TCP connection MUST be<br>   closed.</p>
<p>   When creating more complex topologies, REQ and REP endpoints are<br>   paired in the intermediate nodes to form a forwarding component, so<br>   called “device”.  Device receives requests from the REP endpoint and<br>   forwards them to the REQ endpoint.  At the same time it receives<br>   replies from the REQ endpoint and forwards them to the REP endpoint:</p>
<pre><code>               --- requests --&gt;
</code></pre>
<p>   +—–+   +—–+—–+   +—–+—–+   +—–+<br>   |     |–&gt;|     |     |–&gt;|     |     |–&gt;|     |<br>   | REQ |   | REP | REQ |   | REP | REQ |   | REP |<br>   |     |&lt;–|     |     |&lt;–|     |     |&lt;–|     |<br>   +—–+   +—–+—–+   +—–+—–+   +—–+</p>
<pre><code>               &lt;-- replies ---
</code></pre>
<p>   Using devices, arbitrary complex topologies can be built.  The rest<br>   of this section explains how are the requests routed through a<br>   topology towards processing nodes and how are replies routed back<br>   from processing nodes to the original clients, as well as how the<br>   reliability is achieved.</p>
<p>   The idea for routing requests is to implement a simple coarse-grained<br>   scheduling algorithm based on pushback capabilities of the underlying<br>   transport.</p>
<p>Sustrik                 Expires February 2, 2014                [Page 5]<br><br>Internet-Draft              Request/Reply SP                 August 2013</p>
<p>   The algorithm works by interpreting pushback on a particular channel<br>   as “the part of topology accessible through this channel is busy at<br>   the moment and doesn’t accept any more requests.”</p>
<p>   Thus, when a node is about to send a request, it can choose to send<br>   it only to one of the channels that don’t report pushback at the<br>   moment.  To implement approximately fair distribution of the workload<br>   the node choses a channel from that pool using the round-robin<br>   algorithm.</p>
<p>   As for delivering replies back to the clients, it should be<br>   understood that the client may not be directly accessible (say using<br>   TCP/IP) from the processing node.  It may be beyond a firewall, have<br>   no static IP address etc.  Furthermore, the client and the processing<br>   may not even speak the same transport protocol – imagine client<br>   connecting to the topology using WebSockets and processing node via<br>   SCTP.</p>
<p>   Given the above, it becomes obvious that the replies must be routed<br>   back through the existing topology rather than directly.  In fact,<br>   request/reply topology may be thought of as an overlay network on the<br>   top of underlying transport mechanisms.</p>
<p>   As for routing replies within the request/topology, it is designed in<br>   such a way that each reply contains the whole routing path, rather<br>   than containing just the address of destination node, as is the case<br>   with, for example, TCP/IP.</p>
<p>   The downside of the design is that replies are a little bit longer<br>   and that is in intermediate node gets restarted, all the requests<br>   that were routed through it will fail to complete and will have to be<br>   resent by request/reply end-to-end reliability mechanism.</p>
<p>   The upside, on the other hand, is that the nodes in the topology<br>   don’t have to maintain any routing tables beside the simple table of<br>   adjacent channels along with their IDs.  There’s also no need for any<br>   additional protocols for distributing routing information within the<br>   topology.</p>
<p>   The most important reason for adopting the design though is that<br>   there’s no propagation delay and any nodes becomes accessible<br>   immediately after it is started.  Given that some nodes in the<br>   topology may be extremely short-lived this is a crucial requirement.<br>   Imagine a database client that sends a query, reads the result and<br>   terminates.  It makes no sense to delay the whole process until the<br>   routing tables are synchronised between the client and the server.</p>
<p>Sustrik                 Expires February 2, 2014                [Page 6]<br><br>Internet-Draft              Request/Reply SP                 August 2013</p>
<p>   The algorithm thus works as follows: When request is routed from the<br>   client to the processing node, every REP endpoint determines which<br>   channel it was received from and adds the ID of the channel to the<br>   request.  Thus, when the request arrives at the ultimate processing<br>   node it already contains a full backtrace stack, which in turn<br>   contains all the info needed to route a message back to the original<br>   client.</p>
<p>   After processing the request, the processing node attaches the<br>   backtrace stack from the request to the reply and sends it back to<br>   the topology.  At that point every REP endpoint can check the<br>   traceback and determine which channel it should send the reply to.</p>
<p>   In addition to routing, request/reply protocol takes care of<br>   reliability, i.e. ensures that every request will be eventually<br>   processed and the reply will be delivered to the user, even when<br>   facing failures of processing nodes, intermediate nodes and network<br>   infrastructure.</p>
<p>   Reliability is achieved by simply re-sending the request, if the<br>   reply is not received with a certain timeframe.  To make that<br>   algorithm work flawlessly, the client has to be able to filter out<br>   any stray replies (delayed replies for the requests that we’ve<br>   already received reply to).</p>
<p>   The client thus adds an unique request ID to the request.  The ID<br>   gets copied from the request to the reply by the processing node.<br>   When the reply gets back to the client, it can simply check whether<br>   the request in question is still being processed and if not so, it<br>   can ignore the reply.</p>
<p>   To implement all the functionality described above, messages (both<br>   requests and replies have the following format:</p>
<p>   +-+————+-+————+   +-+————+————-+<br>   |0| Channel ID |0| Channel ID |…|1| Request ID |   payload   |<br>   +-+————+-+————+   +-+————+ ————+</p>
<p>   Payload of the message is preceded by a stack of 32-bit tags.  The<br>   most significant bit of each tag is set to 0 except for the very last<br>   tag.  That allows the algorithm to find out where the tags end and<br>   where the message payload begins.</p>
<p>   As for the remaining 31 bits, they are either request ID (in the last<br>   tag) or a channel ID (in all the remaining tags).  The first channel<br>   ID is added and processed by the REP endpoint closest to the<br>   processing node.  The last channel ID is added and processed by the<br>   REP endpoint closest to the client.</p>
<p>Sustrik                 Expires February 2, 2014                [Page 7]<br><br>Internet-Draft              Request/Reply SP                 August 2013</p>
<p>   Following picture shows an example of request saying “Hello” being<br>   routed from the client through two intermediate nodes to the<br>   processing node and the reply “World” being routed back.  It shows<br>   what messages are passed over the network at each step of the<br>   process:</p>
<pre><code>                       client
                 Hello    |    World
                  |    +-----+    ^
                  |    | REQ |    |
                  V    +-----+    |
           1|823|Hello    |    1|823|World
                  |    +-----+    ^
                  |    | REP |    |
                  |    +-----+    |
                  |    | REQ |    |
                  V    +-----+    |
     0|299|1|823|Hello    |    0|299|1|823|World
                  |    +-----+    ^
                  |    | REP |    |
                  |    +-----+    |
                  |    | REQ |    |
                  V    +-----+    |
</code></pre>
<p>   0|446|0|299|1|823|Hello    |    0|446|0|299|1|823|World<br>                      |    +—–+    ^<br>                      |    | REP |    |<br>                      V    +—–+    |<br>                     Hello    |    World<br>                           service</p>
<ol start="4">
<li> Hop-by-hop vs. End-to-end</li>
</ol>
<p>   All endpoints implement so called “hop-by-hop” functionality.  It’s<br>   the functionality concerned with sending messages to the immediately<br>   adjacent components and receiving messages from them.</p>
<p>   In addition to that, the endpoints on the edge of the topology<br>   implement so called “end-to-end” functionality that is concerned with<br>   issues such as, for example, reliability.</p>
<p>Sustrik                 Expires February 2, 2014                [Page 8]<br><br>Internet-Draft              Request/Reply SP                 August 2013</p>
<pre><code>                  end to end
  +-----------------------------------------+
  |                                         |
</code></pre>
<p>   +—–+   +—–+—–+   +—–+—–+   +—–+<br>   |     |–&gt;|     |     |–&gt;|     |     |–&gt;|     |<br>   | REQ |   | REP | REQ |   | REP | REQ |   | REP |<br>   |     |&lt;–|     |     |&lt;–|     |     |&lt;–|     |<br>   +—–+   +—–+—–+   +—–+—–+   +—–+<br>      |         |     |         |     |         |<br>      +———+     +———+     +———+<br>      hop by hop      hop by hop      hop by hop</p>
<p>   To make an analogy with the TCP/IP stack, IP provides hop-by-hop<br>   functionality, i.e. routing of the packets to the adjacent node,<br>   while TCP implements end-to-end functionality such resending of lost<br>   packets.</p>
<p>   As a rule of thumb, raw hop-by-hop endpoints are used to build<br>   devices (intermediary nodes in the topology) while end-to-end<br>   endpoints are used directly by the applications.</p>
<p>   To prevent confusion, the specification of the endpoint behaviour<br>   below will discuss hop-by-hop and end end-to-end functionality in<br>   separate chapters.</p>
<ol start="5">
<li> Hop-by-hop functionality</li>
</ol>
<p>5.1.  REQ endpoint</p>
<p>   The REQ endpoint is used by the user to send requests to the<br>   processing nodes and receive the replies afterwards.</p>
<p>   When user asks REQ endpoint to send a request, the endpoint should<br>   send it to one of the associated outbound channels (TCP connections<br>   or similar).  The request sent is exactly the message supplied by the<br>   user.  REQ socket MUST NOT modify an outgoing request in any way.</p>
<p>   If there’s no channel to send the request to, the endpoint won’t send<br>   the request and MUST report the backpressure condition to the user.<br>   For example, with BSD socket API, backpressure is reported as EAGAIN<br>   error.</p>
<p>   If there are associated channels but none of them is available for<br>   sending, i.e. all of them are already reporting backpressure, the<br>   endpoint won’t send the message and MUST report the backpressure<br>   condition to the user.</p>
<p>Sustrik                 Expires February 2, 2014                [Page 9]<br><br>Internet-Draft              Request/Reply SP                 August 2013</p>
<p>   Backpressure is used as a means to redirect the requests from the<br>   congested parts of the topology to to the parts that are still<br>   responsive.  It can be thought of as a crude scheduling algorithm.<br>   However crude though, it’s probably still the best you can get<br>   without knowing estimates of execution time for individual tasks, CPU<br>   capacity of individual processing nodes etc.</p>
<p>   Alternatively, backpressure can be thought of as a congestion control<br>   mechanism.  When all available processing nodes are busy, it slows<br>   down the client application, i.e. it prevents the user from sending<br>   any more requests.</p>
<p>   If the channel is not capable of reporting backpressure (e.g.  DCCP)<br>   the endpoint SHOULD consider it as always available for sending new<br>   request.  However, such channels should be used with care as when the<br>   congestion hits they may suck in a lot of requests just to discard<br>   them silently and thus cause re-transmission storms later on.  The<br>   implementation of the REQ endpoint MAY choose to prohibit the use of<br>   such channels altogether.</p>
<p>   When there are multiple channels available for sending the request<br>   endpoint MAY use any prioritisation mechanism to decide which channel<br>   to send the request to.  For example, it may use classic priorities<br>   attached to channels and send message to the channel with the highest<br>   priority.  That allows for routing algorithms such as: “Use local<br>   processing nodes if any are available.  Send the requests to remote<br>   nodes only if there are no local ones available.”  Alternatively, the<br>   endpoint may implement weighted priorities (“send 20% of the request<br>   to node A and 80% to node B).  The endpoint also may not implement<br>   any prioritisation strategy and treat all channels as equal.</p>
<p>   Whatever the case, two rules must apply.</p>
<p>   First, by default the priority settings for all channels MUST be<br>   equal.  Creating a channel with different priority MUST be triggered<br>   by an explicit action by the user.</p>
<p>   Second, if there are several channels with equal priority, the<br>   endpoint MUST distribute the messages among them in fair fashion<br>   using round-robin algorithm.  The round-robin implementation MUST<br>   also take care not to become unfair when new channels are added or<br>   old ones are removed on the fly.</p>
<p>   As for incoming messages, i.e. replies, REQ endpoint MUST fair-queues<br>   them.  In other words, if there are replies available on several<br>   channels, it MUST receive them in a round-robin fashion.  It must<br>   also take care not to compromise the fairness when new channels are<br>   added or old ones removed.</p>
<p>Sustrik                 Expires February 2, 2014               [Page 10]<br><br>Internet-Draft              Request/Reply SP                 August 2013</p>
<p>   In addition to providing basic fairness, the goal of fair-queueing is<br>   to prevent DoS attacks where a huge stream of fake replies from one<br>   channel would be able to block the real replies coming from different<br>   channels.  Fair queueing ensures that messages from every channel are<br>   received at approximately the same rate.  That way, DoS attack can<br>   slow down the system but it can’t entirely block it.</p>
<p>   Incoming replies MUST be handed to the user exactly as they were<br>   received.  REQ endpoint MUST not modify the replies in any way.</p>
<p>5.2.  REP endpoint</p>
<p>   REP endpoint is used to receive requests from the clients and send<br>   replies back to the clients.</p>
<p>   First of all, REP socket is responsible for assigning unique 31-bit<br>   channel IDs to the individual associated channels.</p>
<p>   First ID assigned MUST be random.  Next is computed by adding 1 to<br>   the previous one with potential overflow to 0.</p>
<p>   The implementation MUST ensure that the random number is different<br>   each time the endpoint is re-started, the process that contains it is<br>   restarted or similar.  So, for example, using pseudo-random generator<br>   with a constant seed won’t do.</p>
<p>   The goal of the algorithm is to the spread of possible channel ID<br>   values and thus minimise the chance that a reply is routed to an<br>   unrelated channel, even in the face of intermediate node failures.</p>
<p>   When receiving a message, REP endpoint MUST fair-queue among the<br>   channels available for receiving.  In other words it should round-<br>   robin among such channels and receive one request from a channel at a<br>   time.  It MUST also implement the round-robin algorithm is such a way<br>   that adding or removing channels don’t break its fairness.</p>
<p>   In addition to guaranteeing basic fairness in access to computing<br>   resources the above algorithm makes it impossible for a malevolent or<br>   misbehaving client to completely block the processing of requests<br>   from other clients by issuing steady stream of requests.</p>
<p>   After getting hold on the request, the REP socket should prepend it<br>   by 32 bit value, consisting of 1 bit set to 0 followed by the 31-bit<br>   ID of the channel the request was received from.  The extended<br>   request will be then handed to the user.</p>
<p>   The goal of adding the channel ID to the request is to be able to<br>   route the reply back to the original channel later on.  Thus, when</p>
<p>Sustrik                 Expires February 2, 2014               [Page 11]<br><br>Internet-Draft              Request/Reply SP                 August 2013</p>
<p>   the user sends a reply, endpoint strips first 32 bits off and uses<br>   the value to determine where it is to be routed.</p>
<p>   If the reply is shorter than 32 bits, it is malformed and the<br>   endpoint MUST ignore it.  Also, if the most relevant bit of the<br>   32-bit value isn’t set to 0, the reply is malformed and MUST be<br>   ignored.</p>
<p>   Otherwise, the endpoint checks whether its table of associated<br>   channels contains the channel with a corresponding ID.  If so, it<br>   sends the reply (with first 32 bits stripped off) to that channel.<br>   If the channel is not found, the reply MUST be dropped.  If the<br>   channel is not available for sending, i.e. it is applying<br>   backpressure, the reply MUST be dropped.</p>
<p>   Note that when the reply is unroutable two things might have<br>   happened.  Either there was some kind of network disruption, in which<br>   case the request will be re-sent later on, or the original client<br>   have failed or been shut down.  In such case the request won’t be<br>   resent, however, it doesn’t really matter because there’s no one to<br>   deliver the reply to any more anyway.</p>
<p>   Unlike requests, there’s no pushback applied to the replies; they are<br>   simply dropped.  If the endpoint blocked and waited for the channel<br>   to become available, all the subsequent replies, possibly destined<br>   for different unblocked channels, would be blocked in the meantime.<br>   That allows for a DoS attack simply by firing a lot of requests and<br>   not receiving the replies.</p>
<ol start="6">
<li> End-to-end functionality</li>
</ol>
<p>   End-to-end functionality is built on top of hop-to-hop functionality.<br>   Thus, an endpoint on the edge of a topology contains all the hop-by-<br>   hop functionality, but also implements additional functionality of<br>   its own.  This end-to-end functionality acts basically as a user of<br>   the underlying hop-by-hop functionality.</p>
<p>6.1.  REQ endpoint</p>
<p>   End-to-end functionality for REQ sockets is concerned with re-sending<br>   the requests in case of failure and with filtering out stray or<br>   outdated replies.</p>
<p>   To be able to do the latter, the endpoint must tag the requests with<br>   unique 31-bit request IDs.  First request ID is picked at random.<br>   All subsequent request IDs are generated by adding 1 to the last<br>   request ID and possibly overflowing to 0.</p>
<p>Sustrik                 Expires February 2, 2014               [Page 12]<br><br>Internet-Draft              Request/Reply SP                 August 2013</p>
<p>   To improve robustness of the system, the implementation MUST ensure<br>   that the random number is different each time the endpoint, the<br>   process or the machine is restarted.  Pseudo-random generator with<br>   fixed seed won’t do.</p>
<p>   When user asks the endpoint to send a message, the endpoint prepends<br>   a 32-bit value to the message, consisting of a single bit set to 1<br>   followed by a 31-bit request ID and passes it on in a standard hop-<br>   by-hop way.</p>
<p>   If the hop-by-hop layer reports pushback condition, the end-to-end<br>   layer considers the request unsent and MUST report pushback condition<br>   to the user.</p>
<p>   If the request is successfully sent, the endpoint stores the request<br>   including its request ID, so that it can be resent later on if<br>   needed.  At the same time it sets up a timer to trigger the re-<br>   transmission in case the reply is not received within a specified<br>   timeout.  The user MUST be allowed to specify the timeout interval.<br>   The default timeout interval must be 60 seconds.</p>
<p>   When a reply is received from the underlying hop-by-hop<br>   implementation, the endpoint should strip off first 32 bits from the<br>   reply to check whether it is a valid reply.</p>
<p>   If the reply is shorter than 32 bits, it is malformed and the<br>   endpoint MUST ignore it.  If the most significant bit of the 32-bit<br>   value is set to 0, the reply is malformed and MUST be ignored.</p>
<p>   Otherwise, the endpoint should check whether the request ID in the<br>   reply matches any of the request IDs of the requests being processed<br>   at the moment.  If not so, the reply MUST be ignored.  It is either a<br>   stray message or a duplicate reply.</p>
<p>   Please note that the endpoint can support either one or more requests<br>   being processed in parallel.  Which one is the case depends on the<br>   API exposed to the user and is not part of this specification.</p>
<p>   If the ID in the reply matches one of the requests in progress, the<br>   reply MUST be passed to the user (with the 32-bit prefix stripped<br>   off).  At the same time the stored copy of the original request as<br>   well as re-transmission timer must be deallocated.</p>
<p>   Finally, REQ endpoint MUST make it possible for the user to cancel a<br>   particular request in progress.  What it means technically is<br>   deleting the stored copy of the request and cancelling the associated<br>   timer.  Thus, once the reply arrives, it will be discarded by the<br>   algorithm above.</p>
<p>Sustrik                 Expires February 2, 2014               [Page 13]<br><br>Internet-Draft              Request/Reply SP                 August 2013</p>
<p>   The cancellation allows, for example, the user to time out a request.<br>   They can simply post a request and if there’s no answer in specific<br>   timeframe, they can cancel it.</p>
<p>6.2.  REP endpoint</p>
<p>   End-to-end functionality for REP endpoints is concerned with turning<br>   requests into corresponding replies.</p>
<p>   When user asks to receive a request, the endpoint gets next request<br>   from the hop-by-hop layer and splits it into the traceback stack and<br>   the message payload itself.  The traceback stack is stored and the<br>   payload is returned to the user.</p>
<p>   The algorithm for splitting the request is as follows: Strip 32 bit<br>   tags from the message in one-by-one manner.  Once the most<br>   significant bit of the tag is set, we’ve reached the bottom of the<br>   traceback stack and the splitting is done.  If the end of the message<br>   is reached without finding the bottom of the stack, the request is<br>   malformed and MUST be ignored.</p>
<p>   Note that the payload produced by this procedure is the same as the<br>   request payload sent by the original client.</p>
<p>   Once the user processes the request and sends the reply, the endpoint<br>   prepends the reply with the stored traceback stack and sends it on<br>   using the hop-by-hop layer.  At that point the stored traceback stack<br>   MUST be deallocated.</p>
<p>   Additionally, REP endpoint MUST support cancelling any request being<br>   processed at the moment.  What it means, technically, is that state<br>   associated with the request, i.e. the traceback stack stored by the<br>   endpoint is deleted and reply to that particular request is never<br>   sent.</p>
<p>   The most important use of cancellation is allowing the service<br>   instances to ignore malformed requests.  If the application-level<br>   part of the request doesn’t conform to the application protocol the<br>   service can simply cancel the request.  In such case the reply is<br>   never sent.  Of course, if application wants to send an application-<br>   specific error massage back to the client it can do so by not<br>   cancelling the request and sending a regular reply.</p>
<ol start="7">
<li> Loop avoidance</li>
</ol>
<p>   It may happen that a request/reply topology contains a loop.  It<br>   becomes increasingly likely as the topology grows out of scope of a<br>   single organisation and there are multiple administrators involved in</p>
<p>Sustrik                 Expires February 2, 2014               [Page 14]<br><br>Internet-Draft              Request/Reply SP                 August 2013</p>
<p>   maintaining it.  Unfortunate interaction between two perfectly<br>   legitimate setups can cause loop to be created.</p>
<p>   With no additional guards against the loops, it’s likely that<br>   requests will be caught inside the loop, rotating there forever, each<br>   message gradually growing in size as new prefixes are added to it by<br>   each REP endpoint on the way.  Eventually, a loop can cause<br>   congestion and bring the whole system to a halt.</p>
<p>   To deal with the problem REQ endpoints MUST check the depth of the<br>   traceback stack for every outgoing request and discard any requests<br>   where it exceeds certain threshold.  The threshold should be defined<br>   by the user.  The default value is suggested to be 8.</p>
<ol start="8">
<li> IANA Considerations</li>
</ol>
<p>   New SP endpoint types REQ and REP should be registered by IANA.  For<br>   now, value of 16 should be used for REQ endpoints and value of 17 for<br>   REP endpoints.</p>
<ol start="9">
<li> Security Considerations</li>
</ol>
<p>   The mapping is not intended to provide any additional security to the<br>   underlying protocol.  DoS concerns are addressed within the<br>   specification.</p>
<ol start="10">
<li> References</li>
</ol>
<p>   [SPoverTCP]<br>              Sustrik, M., “TCP mapping for SPs”, August 2013.</p>
<p>Author’s Address</p>
<p>   Martin Sustrik (editor)</p>
<p>   Email: <a href="mailto:&#x73;&#x75;&#115;&#x74;&#114;&#105;&#x6b;&#64;&#50;&#53;&#48;&#98;&#112;&#x6d;&#46;&#x63;&#111;&#109;">&#x73;&#x75;&#115;&#x74;&#114;&#105;&#x6b;&#64;&#50;&#53;&#48;&#98;&#112;&#x6d;&#46;&#x63;&#111;&#109;</a></p>
<p>Sustrik                 Expires February 2, 2014               [Page 15]</p>

    </div>

    
    
    

    <footer class="post-footer">
          <div class="reward-container">
  <div>Buy me a coffee, if you like!</div>
  <button>
    赞赏
  </button>
  <div class="post-reward">
      <div>
        <img src="/images/wechatpay.jpg" alt="郑  君 微信">
        <span>微信</span>
      </div>
      <div>
        <img src="/images/alipay.jpg" alt="郑  君 支付宝">
        <span>支付宝</span>
      </div>

  </div>
</div>

          <div class="post-tags">
              <a href="/tags/zmq/" rel="tag"># zmq</a>
              <a href="/tags/nanomsg/" rel="tag"># nanomsg</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2019/07/15/%E5%8A%9F%E8%83%BD%E5%88%86%E7%B1%BB/%E6%95%B0%E6%8D%AE%E5%BA%93/%E9%80%9A%E7%94%A8/%E6%95%B0%E6%8D%AE%E5%BA%93%E8%AE%BE%E8%AE%A1/" rel="prev" title="数据库设计">
                  <i class="fa fa-chevron-left"></i> 数据库设计
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2019/07/16/%E5%BC%80%E6%BA%90%E5%BA%93/zmq/nanomsg-Q-A/" rel="next" title="nanomsg-Q&A">
                  nanomsg-Q&A <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 2017 – 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">郑  君</span>
</div>
<div class="wordcount">
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-line"></i>
    </span>
    <span title="站点总字数">2.1m</span>
  </span>
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="站点阅读时长">31:18</span>
  </span>
</div>
<div class="busuanzi-count">
    <span class="post-meta-item" id="busuanzi_container_site_uv">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-item" id="busuanzi_container_site_pv">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/pisces/" rel="noopener" target="_blank">NexT.Pisces</a> 强力驱动
  </div>

    </div>
  </footer>

  
  <script src="https://cdn.jsdelivr.net/npm/animejs@3.2.1/lib/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js" integrity="sha256-yt2kYMy0w8AbtF89WXb2P1rfjcP/HTHLT7097U8Y5b8=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/next-boot.js"></script><script src="/js/bookmark.js"></script><script src="/js/code-unfold.js"></script>

  
<script src="https://cdn.jsdelivr.net/npm/hexo-generator-searchdb@1.4.0/dist/search.js" integrity="sha256-vXZMYLEqsROAXkEw93GGIvaB2ab+QW6w3+1ahD9nXXA=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>



  <script src="/js/third-party/fancybox.js"></script>

  <script src="/js/third-party/pace.js"></script>

  
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>





</body>
</html>
